{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ShortAndSweetDemo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83MvujWZRAvD"
      },
      "source": [
        "-----Down and Dirty Demo----\n",
        "\n",
        "So you don't have hours to spend on training up a neural network?\n",
        "Not to worry, step in to our super quick down and dirty edition!\n",
        "If you followed the steps in the README about what you would need loaded before you get started this will take you a little under 10 minutes to complete. (Who doesn't have 10 minutes for this kind of awesomeness?)\n",
        "\n",
        "Alternatively here is our larger [demo](https://colab.research.google.com/drive/1te5e-wfNxUqyPRLCPVMau8Nf3AMlprOB?usp=sharing)  \n",
        "\n",
        "And a much much smaller [dataset](https://drive.google.com/drive/folders/10ldZfWHfqrv20AnGLO9QQdpr2S9493Tz?usp=sharing ) you can use in it! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0uLQQZd7vlN"
      },
      "source": [
        "Quick check list to make sure you are ready to go.\n",
        "1.  Jupyter Notebook      https://jupyter.org/install\n",
        "2.  Python                https://www.python.org/downloads/\n",
        "3.  Python dependencies (use these at you command line)\n",
        "        $ pip install --upgrade tensorflow\n",
        "        $ pip install numpy scipy\n",
        "        $ pip install scikit-learn\n",
        "        $ pip install pillow\n",
        "        $ pip install h5py\n",
        "        $ pip install keras\n",
        "4.  Dataset to test with  https://drive.google.com/drive/folders/156QEK8JuWnFqsHnptc--pRW0lYam8fis?usp=sharing\n",
        "5   Info for saved model  https://drive.google.com/file/d/1LyMNrvk72AVxLWGEQP-B4DAm9wkoc93b/view?usp=sharing\n",
        "\n",
        "6. Alternatively here is our larger demo https://colab.research.google.com/drive/1te5e-wfNxUqyPRLCPVMau8Nf3AMlprOB?usp=sharing and a smaller dataset to use aswell! \n",
        "\n",
        "https://drive.google.com/drive/folders/10ldZfWHfqrv20AnGLO9QQdpr2S9493Tz?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roiajfpP7vlO"
      },
      "source": [
        "If this all checks out, you are good to go!\n",
        "\n",
        "Start with loading all necessacy modules.\n",
        "Tensorflow and Keras will do all the heavy lifting for us putting all the proper components in place to build a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTso1JABRC05"
      },
      "source": [
        "# import all necessary modules\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBhwDmIS7vlQ"
      },
      "source": [
        "Next step we need to set up the variables we used in the model.\n",
        "\n",
        "We processed the images as 256 X 256.\n",
        "\n",
        "Be sure to use 3 for rgb (red, green, blue) setting to designate the images are in color.\n",
        "\n",
        "Next up, set your batch size (how many images you want to process at a time) and the number or epochs (how many times you want to process the batch). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BDv0ilna3d"
      },
      "source": [
        "# set the variables to work with throughout model\n",
        "img_height = 256\n",
        "img_width= 256\n",
        "rgb = 3\n",
        "batch_size = 10  \n",
        "epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VUdYb5-Irsi"
      },
      "source": [
        "We are going to hit the fastforward button now.\n",
        "\n",
        "The next set of steps will just represent additional pieces to the network, but we did our thing that way you don't have.  It is important to take a look over these so you can understand how this works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-EagT4m7vlR"
      },
      "source": [
        "---DATA---\n",
        "\n",
        "This whole nerual net thing doesn't work without data. Sometimes they don't work well without enough data (kind of the point of our whole project).  The following cell (visual purposes only) shows how we brought in our original data and our custom data.  Prepare to be impressed.\n",
        "\n",
        "If you just want to get to the good stuff, you can skip over this one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL_xWcIC7vlR"
      },
      "source": [
        "# We needed to created 4 sets of data to properly train and test the models for accuracy.  This is how we did it\n",
        "\"\"\"\"\n",
        "\n",
        "# set-up training data from the original dataset only\n",
        "ods_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '**local path to directory**', \n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 123,\n",
        "    validation_split = 0.3,\n",
        "    subset = 'training',\n",
        ")\n",
        "\n",
        "# set-up training data using original plus the augmented data as well\n",
        "plusAugmented_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '**local path to directory**',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 123,\n",
        "    validation_split = 0.3,\n",
        "    subset = 'training',\n",
        ")\n",
        "\n",
        "# now create a batch to test ont the plusAugmented model with unseen original images\n",
        "ods_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "   '**local path to directory**', \n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 456,\n",
        "    validation_split = 0.3,\n",
        "    subset = \"validation\",\n",
        ")\n",
        "\n",
        "# also need a batch to test with from the original plus augmented dataset\n",
        "plusAugmented_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '**local path to directory**',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_width),\n",
        "    shuffle = True,\n",
        "    seed = 456,\n",
        "    validation_split = 0.3,\n",
        "    subset = \"validation\",\n",
        ")\n",
        "\"\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MXZOwS_7vlT"
      },
      "source": [
        "We have model variables in place and datasets ready to go at this point.\n",
        "Let's build a model!\n",
        "\n",
        "There is  lot of stuff going on here.  The short version of what is happening is that we are using the spectrogram images (which are pictures of sound across time) to train a neural network that can identify the spoken digits 0-9.  Crazy, right?  Each one ot the layers below serves a specific purpose towards our end goal.  We won't bog you down with details, but if you want to know more I highly advise taking Dr. Phillip's Neural Networks course at Middle Tenneessee State University.  Mind blowing.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4TC19m47vlU"
      },
      "source": [
        "#  build up model\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Convolution2D(16, kernel_size = (5, 5), input_shape=(img_height, img_width, rgb ), activation='relu'))\n",
        "model.add(keras.layers.Convolution2D(16, kernel_size = (3, 3), activation='relu'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "# have to make sure we pass the correct shape to LSTM\n",
        "# use reshape to convert from 2D to 3D!\n",
        "model.add(keras.layers.Reshape((125, -1)))\n",
        "# using TimeDistributed layer\n",
        "# this makes sure the dense layer keeps track of the \n",
        "# temporal aspects of the data\n",
        "model.add(keras.layers.TimeDistributed(layers.Dense(50)))\n",
        "model.add(keras.layers.LSTM(50, return_sequences=False))\n",
        "model.add(keras.layers.Dense(10,activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fURvB-1J7vlV"
      },
      "source": [
        "Now we have a model.  It would be appropriate to high-five yourself at this point.\n",
        "\n",
        "So what in the world does that mean?  Well, the next cell will give us a good visual of what a model is actually comprised of.  Go ahead and run this, then we will explain a bit after."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDjFM0yi7vlV"
      },
      "source": [
        "# display model layers w/ input and output from layers\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHAd6Ao17vlW"
      },
      "source": [
        "The display is of each layer's input and output within the model.  This will give you an idea of how each layer connects moving downstream.  Notice the input of a layer has to match the output of the previous layer.  At the end, you will see the final output is 10 of something.  That my friends, is the final classifications of the images coming through.  The network is going to let us know if the the images it has reviewed are a spoken digit of 0-9.  How cool is that?!?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke2EXVFC7vlW"
      },
      "source": [
        "Okay, so we are almost to the good part.  Next up we would compile our model.  This is going to give us a working function that actually does the hard part of analyzing all the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txmaIUgh7vlW"
      },
      "source": [
        "# compile model   \n",
        "model.compile(optimizer = keras.optimizers.Adam(),\n",
        "             loss = [ keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
        "             metrics = [ keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAxfVCdT7vlW"
      },
      "source": [
        "We saw a visual of the model and its layers. Let's take a quick look now that it is compiled and see what is really going to be moving through this behemoth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqzRE-he7vlX"
      },
      "source": [
        "# show a summary of layers and the parameters\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P07lBdyB7vlX"
      },
      "source": [
        "This gives you a bit more info on what is about to go down.  It displays the total number of parameters that we will be using.  If you are finding this intriguing, after completing this demo I suggest you take a look at the long demo for more details about how you can tweak those numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvN4Rkgb7vlX"
      },
      "source": [
        "Almost there!!\n",
        "\n",
        "So for the next step, we again have doen the heavy lifting for you (and you are welcome).\n",
        "This is where the actual training would occur.  This generally is very time consuming.  The code we used is below.\n",
        "\n",
        "\"\"\"\"\n",
        "# training the original dataset\n",
        "ods_history = model.fit(ods_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1)\n",
        "\"\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRhI6QkY7vlX"
      },
      "source": [
        "Once the training is done, you need to evaluate it for accuracy.  Yep, we did that as well.  Take a look below to see the code and our results.\n",
        "\n",
        "\"\"\"\"\n",
        "# now test the model against the reserved unseen images from the original dataset\n",
        "ods_t = model.evaluate(ods_test, verbose = 1)\n",
        "print(\"Using only original test samples:\")\n",
        "print(\"Accuracy: \", ods_t[1] * 100)\n",
        "print(\"Loss: \", ods_t[0])\n",
        "\"\"\"\"\n",
        "\n",
        "90/90 [==============================] - 5s 44ms/step - loss: 0.9950 - categorical_accuracy: 0.7089\n",
        "Using only original test samples:\n",
        "Accuracy:  70.88888883590698\n",
        "Loss:  0.9950082898139954\n",
        "\n",
        "So when we ran this our accuracy was 70.8%.  Not terrible, but I think we can do better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ko8rISl7vlY"
      },
      "source": [
        "Now we would need to train up the augmented set of data in a model to have something to compare to.  And if you were wondering how long this took, just know that I remodeled my bathroom before it was done. So yes, we saved our results to share with you.\n",
        "\n",
        "\"\"\"\"\n",
        "# next, we need to train with the original plus the augmented data on the exact same architecture\n",
        "plusAugmented_history = model.fit(plusAugmented_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1)\n",
        "\"\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bBYuYUl7vlY"
      },
      "source": [
        "How did it go?\n",
        "\n",
        "\"\"\"\"\n",
        "# now let's test with unseen images from the augmented plus original dataset\n",
        "plusAugmented_history_test = model.evaluate(plusAugmented_test, verbose = 1)\n",
        "print(\"Using the augmented plus original test samples:\")\n",
        "print(\"Accuracy: \", plusAugmented_history_test[1] * 100)\n",
        "print(\"Loss: \", plusAugmented_history_test[0])\n",
        "\"\"\"\"\n",
        "\n",
        "987/987 [==============================] - 46s 46ms/step - loss: 0.1274 - categorical_accuracy: 0.9627\n",
        "Using the augmented plus original test samples:\n",
        "Accuracy:  96.271151304245\n",
        "Loss:  0.12736131250858307\n",
        "\n",
        "Not too shabby, huh?\n",
        "This model validated at 96% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjPyra6w7vlY"
      },
      "source": [
        "Still not done though.  We have one last piece of this mind bending puzzle left.  We have to test the last model against truly unseen images of unaltered sounds.  Use this next piece of code to initialize all of our saved info from this model so you can see for yourself what the results are.\n",
        "\n",
        "Don't forget to use your local file path to access it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XQWZyqp7vlZ"
      },
      "source": [
        "model = keras.models.load_model(\"  **local file path**  \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW96WyW47vlZ"
      },
      "source": [
        "--Quick note--  this is what we got from this model when we ran it.\n",
        "\n",
        "11/11 [==============================] - 2s 17ms/step - loss: 0.0760 - categorical_accuracy: 0.9706\n",
        "Using completely unseen originals only:\n",
        "Accuracy:  97.0588207244873\n",
        "Loss:  0.0760301724076271\n",
        "\n",
        "Comparing the results from the 1st model using zero augmentation (70% accuracy) to this model using the original plus a ton of augmented (97% accuracy) we can see a 27% improvement in accuracy.\n",
        "\n",
        "\"Holy Statistics Batman!!\"  It works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDRStgS27vlZ"
      },
      "source": [
        "Last step..... Let's Goooooooo!\n",
        "\n",
        "Plug in your local file path for the unseen_test image set you downloaded earlier and watch this techno wizardy happen right before your vary eyes!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO520vEv7vla"
      },
      "source": [
        "# NOW, let's test the plusAugmented model with super secret unseen original images\n",
        "unseen_test_history = model.evaluate(unseen_test, verbose = 1)\n",
        "print(\"Using completely unseen originals only:\")\n",
        "print(\"Accuracy: \", unseen_test_history[1] * 100)\n",
        "print(\"Loss: \", unseen_test_history[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gQs-pl17vla"
      },
      "source": [
        "AAAANNNDDDD done... Hope you enjoyed this.  If this sparked an interest for you (and we all know it did), check out the longer demo that gives a full walk through of all our code and more information on how to change things up a bit.  Thanks for spending some time with us!!!"
      ]
    }
  ]
}