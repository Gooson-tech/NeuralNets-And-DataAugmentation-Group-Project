{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import torch\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "\n",
    "from keras.layers import Dropout, LSTM, Conv2D, Dense, TimeDistributed\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "---having issues getting it to load straight from tensorflow, \n",
    "---keep getting error that it is not in the included dataset catalog any longer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds = tfds.load('spoken_digit', split='train', shuffle_files=True)\n",
    "assert isinstance(ds, tf.data.Dataset)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## prep original dataset\n",
    "## prep augmented datasets\n",
    "## normalize data \n",
    "## verify data\n",
    "## display first 10 samples (should be in a spectrograph at this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://jovian.ai/ryku99/spokendigit-feature-extraction\n",
    "## using code from above site\n",
    "## switched to different dataset to try and make some progress, but same concept as spoken_digit\n",
    "## info on dataset can be found at url below\n",
    "https://www.tensorflow.org/datasets/catalog/speech_commands\n",
    "##  \n",
    "\n",
    "\n",
    "data = download_url(\"http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\", \"/content/\")\n",
    "\n",
    "with tarfile.open('/content/speech_commands_v0.01.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall(path='./data')\n",
    "\n",
    "data, sampling_rate = librosa.load('/content/data/one/00176480_nohash_0.wav')\n",
    "data, data.shape, sampling_rate"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Create a CNN-LSTM\n",
    "***----values used in layer to be determined once we get data firmly established-----***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jesse\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "model.add(layers.LSTM(64, stateful=True, return_sequences=True))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Dense(10))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                   optimizer='adam',\n",
    "                   metrics=[tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Show a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1502\u001b[0m     \"\"\"\n\u001b[0;32m   1503\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1504\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1505\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1506\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
    "\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                   optimizer=keras.optimizers.SGD(lr=0.3),\n",
    "                   metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(X,Y,\n",
    "                  batch_size= 100,\n",
    "                  epochs= 100,\n",
    "                  verbose= 1)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= model.evaluate(X,Y, verbose=1)\n",
    "print(\"Loss:\",score[0])\n",
    "print(\"accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach I found @\n",
    "https://machinelearningmastery.com/cnn-long-short-term-memory-networks/\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# define CNN model\n",
    "model.add(TimeDistributed(Conv2D(...))\n",
    "model.add(TimeDistributed(MaxPooling2D(...)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "# define LSTM model\n",
    "model.add(LSTM(...))\n",
    "model.add(Dense(...))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
