{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "PROJ_CODE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgKEKUw8ngrY"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqEsLbIna3a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import librosa, librosa.display\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXzRM3_ygrCO"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BDv0ilna3d"
      },
      "source": [
        "img_height = 256\n",
        "img_width= 256\n",
        "batch_size = 100\n",
        "epochs = 100"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdU7nDvlna3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbebc3f-b9b0-46ab-ea46-9bc7488be779"
      },
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/data', # need local path to directory\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_height),\n",
        "    shuffle = True,\n",
        "    seed = 123,\n",
        "    validation_split = 0.3,\n",
        "    subset = 'training',\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18 files belonging to 4 classes.\n",
            "Using 13 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86IRS8egna3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3b65aa-1f84-4ef0-b656-94dac8aa94f2"
      },
      "source": [
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/data', # need local path to directory\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_height),\n",
        "    shuffle = True,\n",
        "    seed = 456,\n",
        "    validation_split = 0.3,\n",
        "    subset = \"validation\",\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 18 files belonging to 4 classes.\n",
            "Using 5 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veLDvUa1s4Tk"
      },
      "source": [
        "# https://github.com/Ekim-Yurtsever/DeepTL-Lane-Change-Classification\n",
        "#def build_cnn_to_lstm_model(self, input_shape, optimizer=Adam(lr=1e-6, decay=1e-5)):\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.TimeDistributed(layers.Convolution2D(16, 3, 3), input_shape=input_shape))\n",
        "model.add(keras.layers.TimeDistributed(layers.Activation('relu')))\n",
        "model.add(keras.layers.TimeDistributed(layers.Convolution2D(16, 3, 3)))\n",
        "model.add(keras.layers.TimeDistributed(layers.Activation('relu')))\n",
        "model.add(keras.layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2))))\n",
        "model.add(keras.layers.TimeDistributed(layers.Dropout(0.2)))\n",
        "model.add(keras.layers.TimeDistributed(layers.Flatten()))\n",
        "model.add(keras.layers.TimeDistributed(layers.Dense(200)))\n",
        "model.add(keras.layers.TimeDistributed(layers.Dense(50, name=\"first_dense\")))\n",
        "model.add(keras.layers.LSTM(20, return_sequences=False, name=\"lstm_layer\"))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF6Qv5E_rOLv"
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.Adam(),\n",
        "             loss = [ keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
        "             metris = [ keras.metrics.CategoricalAccuracy()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVpTtrU_vEXf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvFjZ7fZna3e"
      },
      "source": [
        "model.fit(ds_train,\n",
        "         batch_size = batch_size,\n",
        "         epochs = epochs,\n",
        "         verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czgf7Xsd8Epp"
      },
      "source": [
        "print('Accuracy: ', model.evaluate([]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFOCAIIorfFm"
      },
      "source": [
        "for training in range(epochs):\n",
        "  for x, y in ds_train:\n",
        "    #training here\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4orfQ5xI13"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuYUJOCQxI7F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po3A88A9xI-B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR-JSlnZxM01"
      },
      "source": [
        "'''\n",
        "# create categorical labels\n",
        "for subdir, dirs, files in os.walk(r'****file location***'):\n",
        "  for filename in files:\n",
        "    label = subdir\n",
        "\n",
        "\n",
        "\n",
        "    filepath = subdir + os.sep + filename\n",
        "    if filepath.endswith(\".png\"):\n",
        "      Base=os.path.basename(filepath)\n",
        "      file_name = os.path.splitext(Base)[0]\n",
        "      #signal, sample_rate = librosa.load(filepath, sr=None)\n",
        "      #sgram = spectrogram(signal, sample_rate)\n",
        "      spec_image = \"sImage\" + file_name + \".png\"\n",
        "      create_image_file (sgram, spec_image)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpM-huCRxQTJ"
      },
      "source": [
        "\"\"\"\n",
        "signal, sr = librosa.load(file, sr = 22050)\n",
        "librosa.display.waveplot(signal, sr = sr)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT5ccq9JxVNx"
      },
      "source": [
        "\"\"\"\n",
        "# use to get fourier transform to display \n",
        "fft = np.fft.fft(signal)\n",
        "magnitude = np.abs(fft)\n",
        "frequency = np.linspace(0 , sr, len(magnitude))\n",
        "plt.plot(frequency, magnitude)\n",
        "plt.xlabel(\"Frefquency\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.show\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVHQGFhIxarJ"
      },
      "source": [
        "\"\"\"\n",
        "# stft-> spectrogram\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "stft = librosa.core.stft(signal, hop_length = hop_length, n_fft = n_n_fft)\n",
        "spectrogram = np.abs(stft)\n",
        "\n",
        "librosa.display.specshow(spectrogram, sr = sr, hop_length = hop_length)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrIcSnw_xqVT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBj-2Vo8xqyW"
      },
      "source": [
        "'''\n",
        "# https://github.com/xingjian-f/DeepLearning-OCR\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten, RepeatVector\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from util import categorical_accuracy_per_sequence\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "def build_CNN_LSTM(channels, width, height, lstm_output_size, nb_classes):\n",
        "\tmodel = Sequential()\n",
        "\t# 1 conv\n",
        "\tmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', \n",
        "\t\tinput_shape=(channels, height, width)))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\t# 2 conv\n",
        "\tmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\t# 3 conv\n",
        "\tmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\t# 4 conv\n",
        "\tmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\t# flaten\n",
        "\ta = model.add(Flatten())\n",
        "\t# 1 dense\n",
        "\tmodel.add(Dense(512, activation='relu'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\t# 2 dense\n",
        "\tmodel.add(Dense(512, activation='relu'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\t# lstm\n",
        "\tmodel.add(RepeatVector(lstm_output_size))\n",
        "\tmodel.add(LSTM(512, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dropout(0.5)))\n",
        "\tmodel.add(TimeDistributed(Dense(nb_classes, activation='softmax')))\n",
        "\tmodel.summary()\n",
        "\tmodel.compile(loss='categorical_crossentropy',\n",
        "\t\t\t\t  optimizer='adam',\n",
        "\t\t\t\t  metrics=[categorical_accuracy_per_sequence],\n",
        "\t\t\t\t  sample_weight_mode='temporal'\n",
        "\t\t\t\t  )\n",
        "\n",
        "\treturn model\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIoVVvF4xz6d"
      },
      "source": [
        "'''\n",
        "# https://github.com/Ekim-Yurtsever/DeepTL-Lane-Change-Classification\n",
        "def build_cnn_to_lstm_model(self, input_shape, optimizer=Adam(lr=1e-6, decay=1e-5)):\n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(Convolution2D(16, 3, 3), input_shape=input_shape))\n",
        "        model.add(TimeDistributed(Activation('relu')))\n",
        "        model.add(TimeDistributed(Convolution2D(16, 3, 3)))\n",
        "        model.add(TimeDistributed(Activation('relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
        "        model.add(TimeDistributed(Dropout(0.2)))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "        model.add(TimeDistributed(Dense(200)))\n",
        "        model.add(TimeDistributed(Dense(50, name=\"first_dense\")))\n",
        "        model.add(LSTM(20, return_sequences=False, name=\"lstm_layer\"))\n",
        "        model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "        self.model = model \n",
        "   '''   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA5je3YyyAqT"
      },
      "source": [
        "\"\"\"\n",
        "model = keras.Sequential([\n",
        "    layer.Input((256,256,1)),\n",
        "    layers.Conv2d(128, (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Dropout(0.25),\n",
        "    #layers.Conv2d(128, (3,3), activation = 'relu', padding = 'same'),\n",
        "    #layers.Dropout(0.25),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.LSTM(100)\n",
        "    #layers.Dense(128, activation = 'relu')\n",
        "    layers.Dense(10, acivation = 'softmax'),\n",
        "    ])\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}