{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "PROJ_CODE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "im1w9kOOna3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d41efa1d-bd3c-4ef3-ebe8-28629b0191da"
      },
      "source": [
        "\"\"\"class MyDataset(tfds.core.GeneratorBasedBuilder):\n",
        "  #DatasetBuilder for my_dataset dataset.\n",
        "\n",
        "  VERSION = tfds.core.Version('1.0.0')\n",
        "  RELEASE_NOTES = {\n",
        "      '1.0.0': 'Initial release.',\n",
        "  }\n",
        "\n",
        "  def _info(self) -> tfds.core.DatasetInfo:\n",
        "    #Dataset metadata (homepage, citation,...).\n",
        "    return tfds.core.DatasetInfo(\n",
        "        builder=self,\n",
        "        features=tfds.features.FeaturesDict({\n",
        "            'image': tfds.features.Image(shape=(256, 256, 3)),\n",
        "            'label': tfds.features.ClassLabel(names=['no', 'yes']),\n",
        "        }),\n",
        "    )\n",
        "\n",
        "  def _split_generators(self, dl_manager: tfds.download.DownloadManager):\n",
        "    #Download the data and define splits.\n",
        "    extracted_path = dl_manager.download_and_extract('http://data.org/data.zip')\n",
        "    # dl_manager returns pathlib-like objects with `path.read_text()`,\n",
        "    # `path.iterdir()`,...\n",
        "    return {\n",
        "        'train': self._generate_examples(path=extracted_path / 'train_images'),\n",
        "        'test': self._generate_examples(path=extracted_path / 'test_images'),\n",
        "    }\n",
        "\n",
        "  def _generate_examples(self, path) -> Iterator[Tuple[Key, Example]]:\n",
        "    #Generator of examples for each split.\n",
        "    for img_path in path.glob('*.jpeg'):\n",
        "      # Yields (key, example)\n",
        "      yield img_path.name, {\n",
        "          'image': img_path,\n",
        "          'label': 'yes' if img_path.name.startswith('yes_') else 'no',\n",
        "      }\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"class MyDataset(tfds.core.GeneratorBasedBuilder):\\n  #DatasetBuilder for my_dataset dataset.\\n\\n  VERSION = tfds.core.Version('1.0.0')\\n  RELEASE_NOTES = {\\n      '1.0.0': 'Initial release.',\\n  }\\n\\n  def _info(self) -> tfds.core.DatasetInfo:\\n    #Dataset metadata (homepage, citation,...).\\n    return tfds.core.DatasetInfo(\\n        builder=self,\\n        features=tfds.features.FeaturesDict({\\n            'image': tfds.features.Image(shape=(256, 256, 3)),\\n            'label': tfds.features.ClassLabel(names=['no', 'yes']),\\n        }),\\n    )\\n\\n  def _split_generators(self, dl_manager: tfds.download.DownloadManager):\\n    #Download the data and define splits.\\n    extracted_path = dl_manager.download_and_extract('http://data.org/data.zip')\\n    # dl_manager returns pathlib-like objects with `path.read_text()`,\\n    # `path.iterdir()`,...\\n    return {\\n        'train': self._generate_examples(path=extracted_path / 'train_images'),\\n        'test': self._generate_examples(path=extracted_path / 'test_images'),\\n    }\\n\\n  def _generate_examples(self, path) -> Iterator[Tuple[Key, Example]]:\\n    #Generator of examples for each split.\\n    for img_path in path.glob('*.jpeg'):\\n      # Yields (key, example)\\n      yield img_path.name, {\\n          'image': img_path,\\n          'label': 'yes' if img_path.name.startswith('yes_') else 'no',\\n      }\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgKEKUw8ngrY"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvqEsLbIna3a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import librosa, librosa.display\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7i2VwpBna3b"
      },
      "source": [
        "##file = ''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWo5Z_fYna3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "a0e4d905-550a-4c68-9349-7ae5cd629b28"
      },
      "source": [
        "\"\"\"\n",
        "signal, sr = librosa.load(file, sr = 22050)\n",
        "librosa.display.waveplot(signal, sr = sr)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[0;32m-> 1184\u001b[0;31m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[0;34m(err, prefix)\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error opening 'data': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3597aeb485ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Amplitude\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VELafn9dna3c"
      },
      "source": [
        "\"\"\"\n",
        "# use to get fourier transform to display \n",
        "fft = np.fft.fft(signal)\n",
        "magnitude = np.abs(fft)\n",
        "frequency = np.linspace(0 , sr, len(magnitude))\n",
        "plt.plot(frequency, magnitude)\n",
        "plt.xlabel(\"Frefquency\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.show\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CY_KbbRna3c"
      },
      "source": [
        "\"\"\"\n",
        "# stft-> spectrogram\n",
        "n_fft = 2048\n",
        "hop_length = 512\n",
        "\n",
        "stft = librosa.core.stft(signal, hop_length = hop_length, n_fft = n_n_fft)\n",
        "spectrogram = np.abs(stft)\n",
        "\n",
        "librosa.display.specshow(spectrogram, sr = sr, hop_length = hop_length)\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gyewPUaMJAw"
      },
      "source": [
        "# https://github.com/xingjian-f/DeepLearning-OCR\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten, RepeatVector\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from util import categorical_accuracy_per_sequence\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "def build_CNN_LSTM(channels, width, height, lstm_output_size, nb_classes):\n",
        "\tmodel = Sequential()\n",
        "\t# 1 conv\n",
        "\tmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', \n",
        "\t\tinput_shape=(channels, height, width)))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\t# 2 conv\n",
        "\tmodel.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\t# 3 conv\n",
        "\tmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\t# 4 conv\n",
        "\tmodel.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
        "\tmodel.add(BatchNormalization(mode=0, axis=1))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "\t# flaten\n",
        "\ta = model.add(Flatten())\n",
        "\t# 1 dense\n",
        "\tmodel.add(Dense(512, activation='relu'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\t# 2 dense\n",
        "\tmodel.add(Dense(512, activation='relu'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\t# lstm\n",
        "\tmodel.add(RepeatVector(lstm_output_size))\n",
        "\tmodel.add(LSTM(512, return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dropout(0.5)))\n",
        "\tmodel.add(TimeDistributed(Dense(nb_classes, activation='softmax')))\n",
        "\tmodel.summary()\n",
        "\tmodel.compile(loss='categorical_crossentropy',\n",
        "\t\t\t\t  optimizer='adam',\n",
        "\t\t\t\t  metrics=[categorical_accuracy_per_sequence],\n",
        "\t\t\t\t  sample_weight_mode='temporal'\n",
        "\t\t\t\t  )\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEqNMqJrMvP-"
      },
      "source": [
        "# https://github.com/Ekim-Yurtsever/DeepTL-Lane-Change-Classification\n",
        "def build_cnn_to_lstm_model(self, input_shape, optimizer=Adam(lr=1e-6, decay=1e-5)):\n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(Convolution2D(16, 3, 3), input_shape=input_shape))\n",
        "        model.add(TimeDistributed(Activation('relu')))\n",
        "        model.add(TimeDistributed(Convolution2D(16, 3, 3)))\n",
        "        model.add(TimeDistributed(Activation('relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
        "        model.add(TimeDistributed(Dropout(0.2)))\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "        model.add(TimeDistributed(Dense(200)))\n",
        "        model.add(TimeDistributed(Dense(50, name=\"first_dense\")))\n",
        "        model.add(LSTM(20, return_sequences=False, name=\"lstm_layer\"))\n",
        "        model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "        self.model = model \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKvDJSF8NUgC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BDv0ilna3d"
      },
      "source": [
        "img_height = 256\n",
        "img_width= 256\n",
        "batch_size = 100\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdU7nDvlna3d"
      },
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'data/*****************', # need local path to directory\n",
        "    labels = 'infered',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_height),\n",
        "    shuffle = true,\n",
        "    seed = ******,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"training\",\n",
        ")\n",
        "\n",
        "display (ds_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86IRS8egna3e"
      },
      "source": [
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'data/*****************', # need local path to directory\n",
        "    labels = 'infered',\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    image_size = (img_height, img_height),\n",
        "    shuffle = true,\n",
        "    seed = ******,\n",
        "    validation_split = 0.1,\n",
        "    subset = \"validation\",\n",
        ")\n",
        "\n",
        "display(ds_validation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWnvytKCna3e"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layer.Input((256,256,1)),\n",
        "    layers.Conv2d(128, (3,3), activation = 'relu', padding = 'same'),\n",
        "    layers.Dropout(0.25),\n",
        "    #layers.Conv2d(128, (3,3), activation = 'relu', padding = 'same'),\n",
        "    #layers.Dropout(0.25),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.LSTM(100)\n",
        "    #layers.Dense(128, activation = 'relu')\n",
        "    layers.Dense(10, acivation = 'softmax'),\n",
        "    ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlVmRIJC8LZ_"
      },
      "source": [
        "model.compile(optimizer = keras.optimizers.Adam(),\n",
        "             loss = [ keras.losses.CategoricalCrossentropy(from_logits=True)],\n",
        "             metris = [ keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvFjZ7fZna3e"
      },
      "source": [
        "model.fit(ds_train,\n",
        "         batch_size = batch_size,\n",
        "         epochs = epochs,\n",
        "         verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czgf7Xsd8Epp"
      },
      "source": [
        "print('Accuracy: ', model.evaluate([]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}